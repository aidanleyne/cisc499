{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363639a7",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8f90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a521ecb",
   "metadata": {},
   "source": [
    "# Combined Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa97ad",
   "metadata": {},
   "source": [
    "#### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eabda4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_combine_embeddings(fpnet_file, taunet_file):\n",
    "    # Load embeddings\n",
    "    embeddings_fpnet = np.loadtxt(fpnet_file, delimiter=',', skiprows=1)\n",
    "    embeddings_taunet = np.loadtxt(taunet_file, delimiter=',', skiprows=1)\n",
    "    # Check if any of the files are empty or have different number of rows\n",
    "    if embeddings_fpnet.shape[0] != embeddings_taunet.shape[0]:\n",
    "        raise ValueError(\"The embeddings files have different number of rows.\")\n",
    "    # Concatenate embeddings\n",
    "    combined_embeddings = np.concatenate((embeddings_fpnet, embeddings_taunet), axis=1)\n",
    "    # L2 normalize the combined embeddings\n",
    "    l2_normalized_embeddings = combined_embeddings / norm(combined_embeddings, axis=1, keepdims=True)\n",
    "    return l2_normalized_embeddings\n",
    "\n",
    "def calculate_rank_n_accuracy(embeddings1, embeddings2, labels1, labels2, n):\n",
    "    correct_matches = 0\n",
    "    for i in range(len(embeddings1)):\n",
    "        # Compute Euclidean distances from embeddings1[i] to all embeddings2\n",
    "        distances = np.linalg.norm(embeddings2 - embeddings1[i], axis=1)\n",
    "        # Get the indices of the top n closest embeddings in embeddings2\n",
    "        closest_indices = np.argsort(distances)[:n]\n",
    "        # Check if the correct label is within these top n closest embeddings\n",
    "        if labels1[i] in labels2[closest_indices]:\n",
    "            correct_matches += 1\n",
    "    # Calculate rank n accuracy\n",
    "    accuracy = correct_matches / len(embeddings1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd4d872",
   "metadata": {},
   "source": [
    "#### Embed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19f1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process embeddings1\n",
    "embeddings1_combined_normalized = load_and_combine_embeddings('embeddings1_fpnet.csv', 'embeddings1_taunet.csv')\n",
    "# Process embeddings2\n",
    "embeddings2_combined_normalized = load_and_combine_embeddings('embeddings2_fpnet.csv', 'embeddings2_taunet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff47ce9",
   "metadata": {},
   "source": [
    "#### Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc52db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexes are equivalent to the user id, both csv's indexes should match\n",
    "labels1 = [i for i in range(0,len(embeddings1_combined_normalized))]\n",
    "labels2 = [i for i in range(0,len(embeddings1_combined_normalized))]\n",
    "labels1 = np.array(labels1)\n",
    "labels2 = np.array(labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed2c429",
   "metadata": {},
   "source": [
    "#### Concatenate and L2 Normalize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb44e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank-1 Accuracy: 0.744068409008792\n",
      "Rank-10 Accuracy: 0.9318318679995182\n",
      "Rank-100 Accuracy: 0.9927736962543658\n"
     ]
    }
   ],
   "source": [
    "# Calculate rank-n accuracies\n",
    "accuracy = calculate_rank_n_accuracy(embeddings1_combined_normalized, embeddings2_combined_normalized, labels1, labels2, 1)\n",
    "accuracy2 = calculate_rank_n_accuracy(embeddings1_combined_normalized, embeddings2_combined_normalized, labels1, labels2, 10)\n",
    "accuracy3 = calculate_rank_n_accuracy(embeddings1_combined_normalized, embeddings2_combined_normalized, labels1, labels2, 100)\n",
    "print(f\"Rank-1 Accuracy: {accuracy}\")\n",
    "print(f\"Rank-10 Accuracy: {accuracy2}\")\n",
    "print(f\"Rank-100 Accuracy: {accuracy3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ebfee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualENV",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
