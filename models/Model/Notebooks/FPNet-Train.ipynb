{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bf08ee",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7219ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/opt/conda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53644001",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6ed2a",
   "metadata": {},
   "source": [
    "#### Define Training Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c410c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"images4_png_4-6/4-6\", \"images4_png_1\", \"images4_png_2\", 'images4_png_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04d592",
   "metadata": {},
   "source": [
    "#### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_paths(folders):\n",
    "    # List of folders\n",
    "    # Create a list of image paths\n",
    "    image_paths = []\n",
    "    for folder in folders:\n",
    "        image_paths += [os.path.join(folder, fname) for fname in os.listdir(folder) if fname.endswith('.png')]\n",
    "    # Ensure the list is sorted\n",
    "    image_paths = sorted(image_paths)\n",
    "    return image_paths\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Read in image path\n",
    "    image = tf.io.read_file(image_path)\n",
    "    # Decode into tensor\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    # Resize for the model \n",
    "    image = tf.image.resize(image, [481, 600])  # Resize as expected by your model\n",
    "    # Cast to an integer for computational simplicity\n",
    "    image = tf.cast(image, tf.uint8)  # Ensure image is uint8\n",
    "    return image\n",
    "\n",
    "def augment(image, label, margin):\n",
    "    # Margin value is (1-probability) of image getting flipped so a margin of .95 equals a 5% chance of augmentation\n",
    "    # Code to flip image left or right\n",
    "    image = tf.cond(tf.random.uniform([], 0, 1) > margin, lambda: tf.image.random_flip_left_right(image), lambda: image)\n",
    "    # Code to flip image up or down \n",
    "    image = tf.cond(tf.random.uniform([], 0, 1) > margin, lambda: tf.image.random_flip_up_down(image), lambda: image)\n",
    "    return image, label\n",
    "\n",
    "def parse_label_from_path(path):\n",
    "    # Uses regex to extract the user name form the image path\n",
    "    match = re.search(r'(\\d+)_keystrokes', path.numpy().decode('utf-8'))\n",
    "    label = int(match.group(1)) if match else 0\n",
    "    # Casts to int and return value\n",
    "    return tf.cast(label, tf.uint8)\n",
    "\n",
    "def load_and_preprocess_data(image_path):\n",
    "    # Wrapper function for preprocessing and parsing image label (username)\n",
    "    image = preprocess_image(image_path)\n",
    "    label = tf_parse_label_from_path(image_path)\n",
    "    return image, label\n",
    "\n",
    "def tf_parse_label_from_path(path):\n",
    "    # Wrapper function\n",
    "    return tf.py_function(parse_label_from_path, [path], Tout=tf.uint8)\n",
    "\n",
    "def shuffle_batch(features, labels):\n",
    "    # Calculate batch size\n",
    "    batch_size = tf.shape(features)[0]\n",
    "    # Create an index to shuffle features and labels in the same order\n",
    "    shuffled_indices = tf.random.shuffle(tf.range(start=0, limit=batch_size))\n",
    "    # Apply gathered indices to shuffle the batch\n",
    "    shuffled_features = tf.gather(features, shuffled_indices)\n",
    "    shuffled_labels = tf.gather(labels, shuffled_indices)\n",
    "    return shuffled_features, shuffled_labels\n",
    "\n",
    "def create_model():\n",
    "    # Creates an untrained FPNet \n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=24, kernel_size=(1,3), activation='relu', input_shape=(481, 600, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(1,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(1,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=None), # No activation on final dense layer\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27c8bc",
   "metadata": {},
   "source": [
    "#### Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building image paths\n",
    "image_paths = build_image_paths(folders)\n",
    "# Assuming 'image_paths' is a list of paths to the images\n",
    "image_paths_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "# Apply the `load_and_preprocess_data` function to each item\n",
    "training_set = image_paths_ds.map(load_and_preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Apply data augmentation only to the training dataset\n",
    "training_set = training_set.map(\n",
    "    lambda image, label: augment(image, label, .95),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "# Batching and prefetching\n",
    "training_set = training_set.batch(256).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420a515e",
   "metadata": {},
   "source": [
    "#### Creating Training Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model check point in case training freezes\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='fpnet_weights.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',  # Change this to 'loss'\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of model\n",
    "model = create_model()\n",
    "# Compile the model with optimizers hyper parameters and loss function as described in \"Device Fingerprinting with Peripheral Timestamps\"\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001, beta_1=.9, beta_2=.999),\n",
    "    loss=tfa.losses.TripletSemiHardLoss()\n",
    ")\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    epochs=100,\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c45b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualENV",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
