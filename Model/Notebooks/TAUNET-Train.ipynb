{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d9a0c3",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d6c28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 20:38:37.470978: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 20:38:37.515502: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 20:38:37.515531: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 20:38:37.517118: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 20:38:37.524860: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 20:38:38.274236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jovyan/virtualENV/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/opt/conda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e4871",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a624c",
   "metadata": {},
   "source": [
    "#### Define Training Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101daed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'keystrokes-training'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f2ba23",
   "metadata": {},
   "source": [
    "#### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b4d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in the training textfiles \n",
    "def read_text_files(directory):\n",
    "    labels = []\n",
    "    features = []\n",
    "    # List all files in the directory and sort them\n",
    "    file_paths = sorted([os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.txt')])\n",
    "    # Process each file\n",
    "    for file_path in tqdm(file_paths, total=len(file_paths), desc=\"Processing text files\"):\n",
    "        # Extract user ID (label) from the filename\n",
    "        user_id = int(os.path.basename(file_path).split('_')[0])\n",
    "        # Read the contents of the file, skipping the first line\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()[1:]  # Skip the \"TIME_DELTA\" line\n",
    "            keystrokes = [int(line.strip()) for line in lines]  # Convert to integers\n",
    "        # Append the extracted data to the lists\n",
    "        labels.append(user_id)\n",
    "        features.append(keystrokes)\n",
    "    return labels, features\n",
    "\n",
    "# Function instance of Taunet\n",
    "def create_model():\n",
    "    # Define the Taunet model architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(256, input_shape=(None, 1)),  \n",
    "        tf.keras.layers.Dense(128, activation=None),  \n",
    "        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Function to shuffle batches if needed\n",
    "def shuffle_batch(features, labels):\n",
    "    # Calculate batch size\n",
    "    batch_size = tf.shape(features)[0]\n",
    "    # Create an index to shuffle features and labels in the same order\n",
    "    shuffled_indices = tf.random.shuffle(tf.range(start=0, limit=batch_size))\n",
    "    # Apply gathered indices to shuffle the batch\n",
    "    shuffled_features = tf.gather(features, shuffled_indices)\n",
    "    shuffled_labels = tf.gather(labels, shuffled_indices)\n",
    "    return shuffled_features, shuffled_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2fe34d",
   "metadata": {},
   "source": [
    "#### Loading In Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5970dcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing text files: 100%|██████████| 233840/233840 [00:40<00:00, 5825.51it/s]\n",
      "2024-04-11 20:39:21.128340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43457 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "labels, features = read_text_files(directory)\n",
    "# Convert intervals and labels into a TensorFlow dataset\n",
    "intervals_tensor = tf.constant(features)\n",
    "labels_tensor = tf.constant(labels)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((intervals_tensor, labels_tensor))\n",
    "dataset = dataset.batch(256)  # Adjust batch size as needed\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae2a500",
   "metadata": {},
   "source": [
    "#### Setup Training Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9873b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='taunet_weights.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',  \n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8d99a",
   "metadata": {},
   "source": [
    "#### Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d428816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 20:39:27.643212: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-04-11 20:39:29.751510: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f02a849f4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-11 20:39:29.751544: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2024-04-11 20:39:29.756629: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712867969.899787   63226 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913/914 [============================>.] - ETA: 0s - loss: 0.9742\n",
      "Epoch 1: loss improved from inf to 0.97418, saving model to taunet_weights.h5\n",
      "914/914 [==============================] - 40s 38ms/step - loss: 0.9742\n",
      "Epoch 2/100\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.9571\n",
      "Epoch 2: loss improved from 0.97418 to 0.95710, saving model to taunet_weights.h5\n",
      "914/914 [==============================] - 34s 38ms/step - loss: 0.9571\n",
      "Epoch 3/100\n",
      "745/914 [=======================>......] - ETA: 6s - loss: 0.9435"
     ]
    }
   ],
   "source": [
    "# Load in model\n",
    "model = create_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001, beta_1=.9, beta_2=.999),\n",
    "    loss=tfa.losses.TripletSemiHardLoss()\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(dataset, epochs=100, verbose=True, callbacks=[model_checkpoint_callback])  # Adjust epochs as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bafd3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualENV",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
