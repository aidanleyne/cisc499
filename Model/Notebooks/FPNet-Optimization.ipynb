{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080ea416",
   "metadata": {},
   "source": [
    "# Grid search code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb27ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders = [\"images4_png_4-6/4-6\", \"images4_png_1\", \"images4_png_2\", 'images4_png_3']\n",
    "test_folders = [\"./images4_png_7-9/7-9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e230c875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 19:36:02.151493: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-09 19:36:02.195655: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-09 19:36:02.195687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-09 19:36:02.197234: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-09 19:36:02.205034: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-09 19:36:02.953014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jovyan/virtualENV/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/opt/conda'\n",
    "\n",
    "def get_paths(folders):\n",
    "    # List of folders\n",
    "    # Create a list of image paths\n",
    "    image_paths = []\n",
    "    for folder in folders:\n",
    "        image_paths += [os.path.join(folder, fname) for fname in os.listdir(folder) if fname.endswith('.png')]\n",
    "    # Ensure the list is sorted\n",
    "    image_paths = sorted(image_paths)\n",
    "    return image_paths\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, [481, 600])  # Resize as expected by your model\n",
    "    image = tf.cast(image, tf.uint8)  # Ensure image is uint8\n",
    "    return image\n",
    "\n",
    "def augment(image, label, margin):\n",
    "    image = tf.cond(tf.random.uniform([], 0, 1) > margin, lambda: tf.image.random_flip_left_right(image), lambda: image)\n",
    "    image = tf.cond(tf.random.uniform([], 0, 1) > margin, lambda: tf.image.random_flip_up_down(image), lambda: image)\n",
    "    # You can add more conditional augmentations here.\n",
    "    return image, label\n",
    "\n",
    "def parse_label_from_path(path):\n",
    "    match = re.search(r'(\\d+)_keystrokes', path.numpy().decode('utf-8'))\n",
    "    label = int(match.group(1)) if match else 0\n",
    "    return tf.cast(label, tf.uint8)\n",
    "\n",
    "def load_and_preprocess_data(image_path):\n",
    "    image = preprocess_image(image_path)\n",
    "    label = tf_parse_label_from_path(image_path)\n",
    "    return image, label\n",
    "\n",
    "def tf_parse_label_from_path(path):\n",
    "    return tf.py_function(parse_label_from_path, [path], Tout=tf.uint8)\n",
    "\n",
    "def calculate_rank_n_accuracy(embeddings1, embeddings2, labels1, labels2, n):\n",
    "    correct_matches = 0\n",
    "    for i in range(len(embeddings1)):\n",
    "        # Compute Euclidean distances from embeddings1[i] to all embeddings2\n",
    "        distances = np.linalg.norm(embeddings2 - embeddings1[i], axis=1)\n",
    "        \n",
    "        # Get the indices of the top 10 closest embeddings in embeddings2\n",
    "        closest_indices = np.argsort(distances)[:n]\n",
    "        \n",
    "        # Check if the correct label is within these top 10 closest embeddings\n",
    "        if labels1[i] in labels2[closest_indices]:\n",
    "            correct_matches += 1\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_matches / len(embeddings1)\n",
    "    return accuracy\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=24, kernel_size=(1,3), activation='relu', input_shape=(481, 600, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(1,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(1,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=None), # No activation on final dense layer\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    "])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(folders):\n",
    "    # Assuming 'image_paths' is a list of paths to the images\n",
    "    image_paths_ds = tf.data.Dataset.from_tensor_slices(get_paths(folders))\n",
    "    # Apply the `load_and_preprocess_data` function to each item\n",
    "    dataset = image_paths_ds.map(load_and_preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def augment_dataset(dataset, augment_set, margin):\n",
    "    def augment(image, label):\n",
    "        image = tf.cond(tf.random.uniform([], 0, 1) > margin, lambda: tf.image.random_flip_left_right(image), lambda: image)\n",
    "        image = tf.cond(tf.random.uniform([], 0, 1) > margin, lambda: tf.image.random_flip_up_down(image), lambda: image)\n",
    "        # You can add more conditional augmentations here.\n",
    "        return image, label\n",
    "\n",
    "    # Apply data augmentation only to the training dataset\n",
    "    if augment_set == True:\n",
    "        dataset = dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # Batching and prefetching\n",
    "    return dataset\n",
    "\n",
    "def batch_dataset(dataset, batch_size):\n",
    "    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38997f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(dataset, optimizer,learning_rate):\n",
    "    # Function to preprocess the images if needed (e.g., resizing)\n",
    "    def preprocess_image_2(image):\n",
    "        # Omit normalization if the model wasn't trained with normalized images\n",
    "        # If there were other preprocessing steps during training, apply them here\n",
    "        return image\n",
    "\n",
    "    # Split the dataset into two parts: for each user, one for each image\n",
    "    images1 = []\n",
    "    images2 = []\n",
    "    labels1 = []\n",
    "    labels2 = []\n",
    "\n",
    "    for image_batch, label_batch in dataset:\n",
    "        images = tf.map_fn(preprocess_image_2, image_batch, dtype=tf.uint8)\n",
    "        # Splitting the images and labels into two separate lists\n",
    "        images1.append(images[::2])  # Take every first image in the pair\n",
    "        images2.append(images[1::2])  # Take every second image in the pair\n",
    "        labels1.append(label_batch[::2])  # Assume labels are the same for both images of a user\n",
    "        labels2.append(label_batch[1::2])\n",
    "\n",
    "    # Concatenate all batches together\n",
    "    images1 = tf.concat(images1, axis=0)\n",
    "    images2 = tf.concat(images2, axis=0)\n",
    "    labels1 = tf.concat(labels1, axis=0)\n",
    "    labels2 = tf.concat(labels2, axis=0)\n",
    "\n",
    "\n",
    "    # Recreate the model architecture\n",
    "    recreated_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=24, kernel_size=(1,3), activation='relu', input_shape=(481, 600, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(1,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(1,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(1,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=None), # No activation on final dense layer\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    "])\n",
    "    opt = optimizer(learning_rate=learning_rate)\n",
    "    # Compile the recreated model\n",
    "    recreated_model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=tfa.losses.TripletSemiHardLoss()\n",
    "    )\n",
    "                    # Load the weights\n",
    "    recreated_model.load_weights('./saved_model/fpnet_test.h5')\n",
    "\n",
    "    # Generate embeddings\n",
    "    # Assuming recreated_model is your model\n",
    "    embeddings1 = recreated_model.predict(images1)\n",
    "    embeddings2 = recreated_model.predict(images2)\n",
    "    labels1 = labels1.numpy()\n",
    "    labels2 = labels2.numpy()\n",
    "    accuracies = calculate_rank_n_accuracy(embeddings1, embeddings2, labels1, labels2, 1)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c231fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='saved_model/fpnet_test.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',  # Change this to 'loss'\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Trying batch size {batch_size}, learning rate {learning_rate}, optimizer {optimizer}\")\n",
    "train = create_dataset(train_folders)\n",
    "train = augment_dataset(train, True, .95)\n",
    "train = batch_dataset(train, 256)\n",
    "\n",
    "#test = create_dataset(test_folders)\n",
    "#test = batch_dataset(test, 16606)\n",
    "\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "learning_rate=.001\n",
    "opt = tf.keras.optimizers.Adam\n",
    "model.compile(optimizer=opt(.001), loss=tfa.losses.TripletSemiHardLoss())\n",
    "history = model.fit(train, epochs=100, verbose=True, callbacks=[model_checkpoint_callback])  # Adjust epochs as needed\n",
    "# Define your parameter grid\n",
    "#val_accuracy = (evaluate(test, opt, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1502cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 19:36:35.409222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43457 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "test = create_dataset(test_folders)\n",
    "test = batch_dataset(test, 16606)\n",
    "val_accuracy = (evaluate(test, tf.keras.optimizers.Adam, .001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0%\n",
    "#For 10 epochs\n",
    "#For 10000 in train, 1000 in test\n",
    "#Augment margin 1\n",
    "#Acc 0.322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5%\n",
    "#For 10 epochs\n",
    "#For 10000 in train, 1000 in test\n",
    "#Augment margin .95\n",
    "#Acc 0.336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10%\n",
    "#For 10 epochs\n",
    "#For 10000 in train, 1000 in test\n",
    "#Augment margin .90\n",
    "#Acc 0.136\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15%\n",
    "#For 10 epochs\n",
    "#For 10000 in train, 1000 in test\n",
    "#Augment margin .85\n",
    "#Acc 0.256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20%\n",
    "#For 10 epochs\n",
    "#For 10000 in train, 1000 in test\n",
    "#Augment margin .80\n",
    "#Acc 0.222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25%\n",
    "#For 10 epochs\n",
    "#For 10000 in train, 1000 in test\n",
    "#Augment margin .75\n",
    "#Acc 0.222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5d960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualENV",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
